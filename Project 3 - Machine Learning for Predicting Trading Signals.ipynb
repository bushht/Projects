{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Bushra Hoteit**"
      ],
      "metadata": {
        "id": "rfI1umN1rZ9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yss6q9TwrXne"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE PROJECT 2 & SAVE IT AS CLEANED DATA"
      ],
      "metadata": {
        "id": "y_JW5YHkuqV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  if not os.path.exists(\"historical_stocks.csv\") or not os.path.exists(\"historical_stock_prices.csv\"):\n",
        "    raise FileNotFoundError(\"CSV files not found. Please ensure it is in your working directory.\")\n",
        "  else:\n",
        "    stocks=pd.read_csv(\"historical_stocks.csv\", encoding='utf-8')\n",
        "    stock_prices=pd.read_csv(\"historical_stock_prices.csv\", encoding='utf-8')\n",
        "  if stocks.empty or stock_prices.empty:\n",
        "    raise ValueError(\"One or both of the files loaded are empty. Please check the data.\")\n",
        "  print(\"Successfully loaded both datasets!\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"Error loading data: {str(e)}\")\n",
        "  raise\n"
      ],
      "metadata": {
        "id": "iYsoN6G9rr4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_prices['date'] = pd.to_datetime(stock_prices['date'])\n",
        "data = pd.merge(stocks, stock_prices, on='ticker')\n",
        "data.set_index('date', inplace=True)\n",
        "data.sort_index(inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "f-KvE1K7sBjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Feature Engineering with Technical Indicators**"
      ],
      "metadata": {
        "id": "SRoZi6Sls_64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Moving Average Convergence Divergence (MACD)***"
      ],
      "metadata": {
        "id": "cTgCPZMrx8Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EMA(data, period =12, column='close'):\n",
        "  return data[column].ewm(span = period, adjust = False).mean()\n",
        "\n",
        "data['EMA12'] = EMA(data, period = 12)\n",
        "data['EMA26'] = EMA(data, period = 26)\n",
        "data['MACD'] = data['EMA12'] - data['EMA26']\n",
        "data['Signal_Line'] = EMA(data, period = 9, columns='MACD')\n",
        "\n",
        "\n",
        "data['Buy_Signal_MACD'] = data['MACD'] > data['Signal_Line']\n",
        "data['Sell_Signal_MACD'] = data['MACD'] < data['Signal_Line']\n"
      ],
      "metadata": {
        "id": "P5Vl21gzsq_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Relative Strength Index (RSI)***"
      ],
      "metadata": {
        "id": "cOS-1Y3lyCBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RSI(data, period = 14):\n",
        "  delta = data['close'].diff()\n",
        "  gain = (delta.where(delta > 0, 0).ewm(span = period, adjust = False).mean())\n",
        "  loss = (-delta.where(delta < 0, 0).ewm(span = period, adjust = False).mean())\n",
        "  RS = gain / loss\n",
        "  return (100 - (100 / (1 + RS)))\n",
        "\n",
        "data['RSI'] = RSI(data)"
      ],
      "metadata": {
        "id": "GRHe8fPyx_Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Buy_Signal_RSI'] = data['RSI'] < 30\n",
        "data['Sell_Signal_RSI'] = data['RSI'] > 70\n",
        "data.head()"
      ],
      "metadata": {
        "id": "lw_bYfVlx04C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Signal'] = np.where(data['Buy_Signal_MACD'] & data['Buy_Signal_RSI'], 'Buy',\n",
        "                          np.where(data['Sell_Signal_MACD'] & data['Sell_Signal_RSI'], 'Sell', 'Hold'))\n",
        "data.head()"
      ],
      "metadata": {
        "id": "qHbG6uiuyI1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Data Preparation and Splitting**"
      ],
      "metadata": {
        "id": "m1WUKQsuzuJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Integrate the indicators and the signals into the main dataset. Use the signals computed above as ground-truth labels for the dataset. Split the data into training and testing sets.***"
      ],
      "metadata": {
        "id": "9NIuLwVO1LXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(0, inplace=True)\n",
        "\n",
        "features = ['RSI', 'MACD', 'volume', 'rolling_avg', 'volatility']\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data['Signal'], test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "vfpcB7F5zxP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Model Building and Validation**"
      ],
      "metadata": {
        "id": "Y0lvZ0T61N9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement 1-Logistic Regression, 2-Random Forests, 3-Support Vector Machines (SVM). Train the models on the training set and validate their performance. Training them can be time-consuming, depending on your computer's processing power.***"
      ],
      "metadata": {
        "id": "-aHAIMAy1vdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_pred = lr_model.predict(X_test)"
      ],
      "metadata": {
        "id": "xNGjyo-t1Qi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forests\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "BdxsFoFt1xbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "jECYyRFs10V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Model Evaluation and Optimization**"
      ],
      "metadata": {
        "id": "azZpYcGX15RM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluate the models on the test set. Optimize the models based on evaluation metrics and adjust hyperparameters as needed to improve performance. Use cross-validation where applicable to ensure the robustness of the evaluation***"
      ],
      "metadata": {
        "id": "KnJVGMQl17dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(predictions, actual):\n",
        "  accuracy = accuracy_score(actual, predictions)\n",
        "  return accuracy\n",
        "\n",
        "lr_metrics = evaluate_model(lr_pred, y_test)\n",
        "rf_metrics = evaluate_model(rf_pred, y_test)\n",
        "svm_metrics = evaluate_model(svm_pred, y_test)\n"
      ],
      "metadata": {
        "id": "cPkfzarq2CoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Reporting and Documentation**"
      ],
      "metadata": {
        "id": "GrxB6hDc1_4x"
      }
    }
  ]
}
